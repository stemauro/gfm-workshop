{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T08:54:00.987492Z",
     "start_time": "2024-09-20T08:54:00.984640Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Segmentation Models PyTorch Factory\n",
    "\n",
    "You can use the `SMPModelFactory` to initialize segmentation tasks in TerraTorch. Note that not all models support more than 3 channels (e.g., MiT models)."
   ],
   "id": "8c1711c4f385ca00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:05:07.582237Z",
     "start_time": "2024-09-20T09:05:07.578815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from segmentation_models_pytorch.encoders import encoders as smp_encoders\n",
    "print(f'Available SMP backbones: \\n{\", \".join(smp_encoders)}')"
   ],
   "id": "d6f57865511d83f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available SMP backbones: \n",
      "resnet18, resnet34, resnet50, resnet101, resnet152, resnext50_32x4d, resnext101_32x4d, resnext101_32x8d, resnext101_32x16d, resnext101_32x32d, resnext101_32x48d, dpn68, dpn68b, dpn92, dpn98, dpn107, dpn131, vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, vgg19_bn, senet154, se_resnet50, se_resnet101, se_resnet152, se_resnext50_32x4d, se_resnext101_32x4d, densenet121, densenet169, densenet201, densenet161, inceptionresnetv2, inceptionv4, efficientnet-b0, efficientnet-b1, efficientnet-b2, efficientnet-b3, efficientnet-b4, efficientnet-b5, efficientnet-b6, efficientnet-b7, mobilenet_v2, xception, timm-efficientnet-b0, timm-efficientnet-b1, timm-efficientnet-b2, timm-efficientnet-b3, timm-efficientnet-b4, timm-efficientnet-b5, timm-efficientnet-b6, timm-efficientnet-b7, timm-efficientnet-b8, timm-efficientnet-l2, timm-tf_efficientnet_lite0, timm-tf_efficientnet_lite1, timm-tf_efficientnet_lite2, timm-tf_efficientnet_lite3, timm-tf_efficientnet_lite4, timm-resnest14d, timm-resnest26d, timm-resnest50d, timm-resnest101e, timm-resnest200e, timm-resnest269e, timm-resnest50d_4s2x40d, timm-resnest50d_1s4x24d, timm-res2net50_26w_4s, timm-res2net101_26w_4s, timm-res2net50_26w_6s, timm-res2net50_26w_8s, timm-res2net50_48w_2s, timm-res2net50_14w_8s, timm-res2next50, timm-regnetx_002, timm-regnetx_004, timm-regnetx_006, timm-regnetx_008, timm-regnetx_016, timm-regnetx_032, timm-regnetx_040, timm-regnetx_064, timm-regnetx_080, timm-regnetx_120, timm-regnetx_160, timm-regnetx_320, timm-regnety_002, timm-regnety_004, timm-regnety_006, timm-regnety_008, timm-regnety_016, timm-regnety_032, timm-regnety_040, timm-regnety_064, timm-regnety_080, timm-regnety_120, timm-regnety_160, timm-regnety_320, timm-skresnet18, timm-skresnet34, timm-skresnext50_32x4d, timm-mobilenetv3_large_075, timm-mobilenetv3_large_100, timm-mobilenetv3_large_minimal_100, timm-mobilenetv3_small_075, timm-mobilenetv3_small_100, timm-mobilenetv3_small_minimal_100, timm-gernet_s, timm-gernet_m, timm-gernet_l, mit_b0, mit_b1, mit_b2, mit_b3, mit_b4, mit_b5, mobileone_s0, mobileone_s1, mobileone_s2, mobileone_s3, mobileone_s4\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:05:54.007879Z",
     "start_time": "2024-09-20T09:05:53.499383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from terratorch.datasets import HLSBands\n",
    "from terratorch.models import SMPModelFactory\n",
    "\n",
    "# We use the 6 bands from the HLS Brun Scars dataset.\n",
    "hls_bands = [\n",
    "    HLSBands.BLUE,\n",
    "    HLSBands.GREEN,\n",
    "    HLSBands.RED,\n",
    "    HLSBands.NIR_NARROW,\n",
    "    HLSBands.SWIR_1,\n",
    "    HLSBands.SWIR_2,\n",
    "]\n",
    "\n",
    "# Let's build a segmentation model using segmentation models pytorch\n",
    "model = SMPModelFactory().build_model(\n",
    "    task=\"segmentation\",\n",
    "    backbone=\"resnet50\", # see smp_encoders.keys()\n",
    "    model='Unet', # 'DeepLabV3', 'DeepLabV3Plus', 'FPN', 'Linknet', 'MAnet', 'PAN', 'PSPNet', 'Unet', 'UnetPlusPlus' \n",
    "    bands=hls_bands,\n",
    "    in_channels=6,\n",
    "    num_classes=2,\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "# Not all models support more than 3 channels (e.g., MiT models)."
   ],
   "id": "89046fbe21be2b2a",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T08:46:48.619973Z",
     "start_time": "2024-09-20T08:46:48.454527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Running a test with the model \n",
    "\n",
    "trial_data = torch.zeros(2, 6, 224, 224) # batch_size, channels, height, width\n",
    "output = model(trial_data)\n",
    "print(f\"Features has shape {output.output.shape}\")"
   ],
   "id": "628bbed13a9a0b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features has shape torch.Size([2, 2, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Datamodule\n",
    "You can create datamodules for training by leveraging one of our generic data modules. Alternatively, creating your own subclasses of `torchgeo.datamodules.GeoDataModule` or `torchgeo.datamodules.NonGeoDataModule`.\n",
    "\n",
    "Datamodules package train, test and validation datasets as well as any transforms done.\n",
    "\n",
    "Any [TorchGeo](https://torchgeo.readthedocs.io/en/stable/) datamodule will also be compatible with TerraTorch.\n",
    "\n",
    "## Example\n",
    "\n",
    "Let's use the burn scar segmentation dataset as an example (https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars)."
   ],
   "id": "82c09681defccfed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:30:56.742314Z",
     "start_time": "2024-09-20T09:30:56.738928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATASET_PATH = 'data/HLSBurnScars'\n",
    "\n",
    "# Let's download the dataset (~5GB)\n",
    "if not os.path.isdir(os.path.join(DATASET_PATH, 'validation')):\n",
    "    import subprocess\n",
    "    os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "    subprocess.run('wget https://huggingface.co/datasets/ibm-nasa-geospatial/hls_burn_scars/resolve/main/hls_burn_scars.tar.gz', shell=True, check=True)\n",
    "    subprocess.run(f'tar -xvzf hls_burn_scars.tar.gz -C {DATASET_PATH}', shell=True, check=True)\n",
    "    os.remove('hls_burn_scars.tar.gz')"
   ],
   "id": "b2623de87cd5047f",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:30:56.910844Z",
     "start_time": "2024-09-20T09:30:56.902004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule\n",
    "\n",
    "# from https://github.com/NASA-IMPACT/hls-foundation-os/blob/main/configs/burn_scars.py\n",
    "means=[\n",
    "        0.033349706741586264,\n",
    "        0.05701185520536176,\n",
    "        0.05889748132001316,\n",
    "        0.2323245113436119,\n",
    "        0.1972854853760658,\n",
    "        0.11944914225186566,\n",
    "    ]\n",
    "stds=[\n",
    "        0.02269135568823774,\n",
    "        0.026807560223070237,\n",
    "        0.04004109844362779,\n",
    "        0.07791732423672691,\n",
    "        0.08708738838140137,\n",
    "        0.07241979477437814,\n",
    "    ]\n",
    "\n",
    "# For 3 channel RGB models, you might want to use the ImageNet values: \n",
    "# mean = [0.485, 0.456, 0.406]\n",
    "# stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "datamodule = GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=4,\n",
    "    num_workers=0,\n",
    "    train_data_root=os.path.join(DATASET_PATH, 'training'),\n",
    "    val_data_root=os.path.join(DATASET_PATH, 'validation'),\n",
    "    test_data_root=os.path.join(DATASET_PATH, 'validation'), # We are reusing the validation set for testing \n",
    "    img_grep=\"*_merged.tif\",\n",
    "    label_grep=\"*.mask.tif\",\n",
    "    means=means,\n",
    "    stds=stds,\n",
    "    num_classes=2,\n",
    "\n",
    "    # if transforms are defined with Albumentations, you can pass them here\n",
    "    # train_transform=train_transform,\n",
    "    # val_transform=val_transform,\n",
    "    # test_transform=test_transform,\n",
    "\n",
    "    # Bands of your dataset (in this case similar to the model bands)\n",
    "    dataset_bands=hls_bands,\n",
    "    # Input bands of your model\n",
    "    output_bands=hls_bands,\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    ")\n",
    "# we want to access some properties of the train dataset later on, so lets call setup here\n",
    "# if not, we would not need to\n",
    "datamodule.setup(\"fit\")"
   ],
   "id": "5a1ed982fa809514",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lightning Trainers\n",
    "At the highest level of abstraction, you can operate with task specific trainers. These encapsulate the model, loss, optimizer and any training hyperparameters.\n",
    "\n",
    "They build on the model factory we introduced previously and are able to take any. To use a task with a model not supported by a currently existing model factory, simply create your own model factory!\n",
    "\n",
    "Let's create a Trainer for Semantic Segmentation."
   ],
   "id": "c95ef947be616ef8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:30:58.985260Z",
     "start_time": "2024-09-20T09:30:58.475305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from terratorch.tasks import SemanticSegmentationTask\n",
    "\n",
    "model_args = {\n",
    "        \"backbone\":\"resnet50\", # see smp_encoders.keys()\n",
    "        'model': 'Unet', # 'DeepLabV3', 'DeepLabV3Plus', 'FPN', 'Linknet', 'MAnet', 'PAN', 'PSPNet', 'Unet', 'UnetPlusPlus' \n",
    "        \"bands\": hls_bands,\n",
    "        \"in_channels\": 6,\n",
    "        \"num_classes\": 2,\n",
    "        \"pretrained\": True,\n",
    "}\n",
    "\n",
    "task = SemanticSegmentationTask(\n",
    "    model_args=model_args,\n",
    "    model_factory=\"SMPModelFactory\",\n",
    "    loss=\"ce\",\n",
    "    lr=1e-4,\n",
    "    ignore_index=-1,\n",
    "    optimizer=\"AdamW\",\n",
    "    optimizer_hparams={\"weight_decay\": 0.05},\n",
    "    freeze_backbone=True,\n",
    "    class_names=['Not burned', 'Burned'],\n",
    "    class_weights=[0.1, 0.9]\n",
    ")"
   ],
   "id": "5d64dedcf582c53f",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T09:32:03.414907Z",
     "start_time": "2024-09-20T09:31:03.644418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint, RichProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=task.monitor, save_top_k=1, save_last=True)\n",
    "early_stopping_callback = EarlyStopping(monitor=task.monitor, min_delta=0.00, patience=20)\n",
    "logger = TensorBoardLogger(save_dir='output', name='tutorial')\n",
    "\n",
    "# You can also log directly to WandB\n",
    "# from lightning.pytorch.loggers import WandbLogger\n",
    "# wandb_logger = WandbLogger(log_model=\"all\") \n",
    "\n",
    "trainer = Trainer(\n",
    "    devices=1, # Number of GPUs. Interactive mode recommended with 1 device\n",
    "    precision=\"16-mixed\",\n",
    "    callbacks=[\n",
    "        RichProgressBar(),\n",
    "        checkpoint_callback,\n",
    "        early_stopping_callback,\n",
    "        LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "    ],\n",
    "    logger=logger,\n",
    "    max_epochs=1, # train only one epoch for demo\n",
    "    default_root_dir='output/tutorial',\n",
    "    log_every_n_steps=1,\n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "_ = trainer.fit(model=task, datamodule=datamodule)"
   ],
   "id": "706bc5b0f5da7c5e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mName         \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mType            \u001B[0m\u001B[1;35m \u001B[0m┃\u001B[1;35m \u001B[0m\u001B[1;35mParams\u001B[0m\u001B[1;35m \u001B[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001B[2m \u001B[0m\u001B[2m0\u001B[0m\u001B[2m \u001B[0m│ model         │ SMPModelWrapper  │ 32.5 M │\n",
       "│\u001B[2m \u001B[0m\u001B[2m1\u001B[0m\u001B[2m \u001B[0m│ criterion     │ CrossEntropyLoss │      0 │\n",
       "│\u001B[2m \u001B[0m\u001B[2m2\u001B[0m\u001B[2m \u001B[0m│ train_metrics │ MetricCollection │      0 │\n",
       "│\u001B[2m \u001B[0m\u001B[2m3\u001B[0m\u001B[2m \u001B[0m│ val_metrics   │ MetricCollection │      0 │\n",
       "│\u001B[2m \u001B[0m\u001B[2m4\u001B[0m\u001B[2m \u001B[0m│ test_metrics  │ MetricCollection │      0 │\n",
       "└───┴───────────────┴──────────────────┴────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model         │ SMPModelWrapper  │ 32.5 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion     │ CrossEntropyLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ train_metrics │ MetricCollection │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ val_metrics   │ MetricCollection │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ test_metrics  │ MetricCollection │      0 │\n",
       "└───┴───────────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mTrainable params\u001B[0m: 9.0 M                                                                                            \n",
       "\u001B[1mNon-trainable params\u001B[0m: 23.5 M                                                                                       \n",
       "\u001B[1mTotal params\u001B[0m: 32.5 M                                                                                               \n",
       "\u001B[1mTotal estimated model params size (MB)\u001B[0m: 130                                                                        \n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 9.0 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 23.5 M                                                                                       \n",
       "<span style=\"font-weight: bold\">Total params</span>: 32.5 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 130                                                                        \n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e3b13597a554eac9f2770bfd4a5e4ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T08:56:02.167413Z",
     "start_time": "2024-09-20T08:55:49.306963Z"
    }
   },
   "cell_type": "code",
   "source": "res = trainer.test(model=task, datamodule=datamodule)",
   "id": "2d92341bdd5653bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a9e360b8ce443998726c331979601c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1m             Test metric              \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m             DataLoader 0             \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001B[36m \u001B[0m\u001B[36m       test/Multiclass_Accuracy       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.9042260646820068          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m       test/Multiclass_F1_Score       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.9042260646820068          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m    test/Multiclass_Jaccard_Index     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.6812360286712646          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m test/Multiclass_Jaccard_Index_Micro  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.8251940011978149          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m              test/loss               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m         0.28467822074890137          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m    test/multiclassaccuracy_Burned    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.906612753868103           \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m  test/multiclassaccuracy_Not burned  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.9039826393127441          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36m  test/multiclassjaccardindex_Burned  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m         0.46701979637145996          \u001B[0m\u001B[35m \u001B[0m│\n",
       "│\u001B[36m \u001B[0m\u001B[36mtest/multiclassjaccardindex_Not burned\u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m          0.8954523205757141          \u001B[0m\u001B[35m \u001B[0m│\n",
       "└────────────────────────────────────────┴────────────────────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">              Test metric               </span>┃<span style=\"font-weight: bold\">              DataLoader 0              </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Multiclass_Accuracy        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.9042260646820068           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Multiclass_F1_Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.9042260646820068           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Multiclass_Jaccard_Index      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.6812360286712646           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Multiclass_Jaccard_Index_Micro   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.8251940011978149           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">               test/loss                </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.28467822074890137           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/multiclassaccuracy_Burned     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.906612753868103            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/multiclassaccuracy_Not burned   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.9039826393127441           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/multiclassjaccardindex_Burned   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">          0.46701979637145996           </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test/multiclassjaccardindex_Not burned </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.8954523205757141           </span>│\n",
       "└────────────────────────────────────────┴────────────────────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T08:59:56.462141Z",
     "start_time": "2024-09-20T08:59:04.936504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze training in tensorboard\n",
    "!tensorboard --logdir output/ --port 9010  # add --host $(hostname -f) for clusters"
   ],
   "id": "c24e4b187fcf27e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\r\n",
      "TensorBoard 2.17.1 at http://Thornhill:9010/ (Press CTRL+C to quit)\r\n",
      "^C\r\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CLI tool\n",
    "\n",
    "You find an example for SMP models in `configs/burnscars_smp.yaml` that you can run with `terratorch fit -c configs/burnscars_smp.yaml`. "
   ],
   "id": "d5fc5fd69d827d7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9e86e3208bf47d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
